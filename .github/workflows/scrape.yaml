name: Scrape

on:
  push:
    paths:
      # Only run a new workflow every time this file (scrape.yml) file has changed
      - .github/workflows/scrape.yaml
  # Required configuration in order to run a workflow manually
  workflow_dispatch: 
  schedule:
    # Run this workflow at 12:00 p.m. (noon) every day
    - cron: '0 12 * * *'

jobs:
  scheduled:
    # Run on a fresh virtual machine hosted by GitHub
    runs-on: ubuntu-latest
    steps:
      # The first step is to check out the repository so it can read the files inside of it and do other operations
      - name: Check out repo
        uses: actions/checkout@v2
      # The second step installs Deno, which is a new Javascript runtime that improves on Node, used for postprocessing later
      - name: Setup deno
        uses: denoland/setup-deno@main
        with:
          deno-version: v1.x
      # The third step is a 'Flat Action' step--- we fetch the data in the 'http_url' and save it as 'downloaded_filename'
      - name: Fetch data 
        uses: githubocto/flat@v3
        with:
          # The endpoint from which data is to be fetched at 12:00 p.m. (noon) every day
          http_url: https://api.coindesk.com/v2/bpi/currentprice.json
          # The http_url is saved and renamed in the repository as 'btc-price.json'
          downloaded_filename: btc-price.json
